{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalized Medicine: Redefining Cancer Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan\n",
    "\n",
    "1. Process data and display some example images to get an idea of what's going on\n",
    "2. Train VGG model (multi-input?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# Import utility libraries\n",
    "import os, sys\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import cv2 # OpenCV (Open Source Computer Vision Library). Image manipulation, for our purposes\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import io\n",
    "from tqdm import tqdm # Progress bars\n",
    "\n",
    "# Allow importing utils, Vgg, etc. from the parent directory\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "NOTEBOOK_DIR = current_dir\n",
    "DATA_DIR = os.path.dirname(current_dir) + \"/data/cancer_treatment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample data\n",
    "\n",
    "# Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data should be extracted and unzipped at this point, from $DATA_DIR:\n",
    "\n",
    "```\n",
    "unzip *.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/data/cancer_treatment\n",
      "/home/ubuntu/nbs/cancer-treatment\n"
     ]
    }
   ],
   "source": [
    "%mkdir -p $DATA_DIR\n",
    "%cd $DATA_DIR\n",
    "\n",
    "# Set up sample data\n",
    "# !mkdir -p sample-jpg/train\n",
    "# !find train-jpg -type f | shuf -n 1000 | xargs -I {} cp \"{}\" sample-jpg/train\n",
    "# !mkdir -p sample-jpg/valid\n",
    "# !find train-jpg -type f | shuf -n 250 | xargs -I {} cp \"{}\" sample-jpg/valid\n",
    "\n",
    "# Set up validation data (n.b. we `mv` files here instead of `cp` since we don't want overlap between training and validation data)\n",
    "# !mkdir -p valid-jpg\n",
    "# !find train-jpg -type f | shuf -n 8000 | xargs -I {} mv \"{}\" valid-jpg\n",
    "\n",
    "!mkdir results\n",
    "\n",
    "%cd $NOTEBOOK_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize train and test numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = [] # Training input\n",
    "x_test = [] # Test input\n",
    "y_train = [] # Expected training output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and inspect training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(DATA_DIR + \"/train_v2.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['slash_burn', 'clear', 'blooming', 'primary', 'cloudy', 'conventional_mine', 'water', 'haze', 'cultivation', 'partly_cloudy', 'artisinal_mine', 'habitation', 'bare_ground', 'blow_down', 'agriculture', 'road', 'selective_logging']\n"
     ]
    }
   ],
   "source": [
    "# Extract labels\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "# Take all values of 'tags' key in df_train, split on spaces, flatten it, turn it into a set (extract unique values), and then back to a list\n",
    "labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'selective_logging': 16, 'cultivation': 8, 'clear': 1, 'habitation': 11, 'conventional_mine': 5, 'cloudy': 4, 'primary': 3, 'water': 6, 'haze': 7, 'slash_burn': 0, 'partly_cloudy': 9, 'artisinal_mine': 10, 'blooming': 2, 'bare_ground': 12, 'blow_down': 13, 'agriculture': 14, 'road': 15}\n",
      "{0: 'slash_burn', 1: 'clear', 2: 'blooming', 3: 'primary', 4: 'cloudy', 5: 'conventional_mine', 6: 'water', 7: 'haze', 8: 'cultivation', 9: 'partly_cloudy', 10: 'artisinal_mine', 11: 'habitation', 12: 'bare_ground', 13: 'blow_down', 14: 'agriculture', 15: 'road', 16: 'selective_logging'}\n"
     ]
    }
   ],
   "source": [
    "label_map = {l: i for i, l in enumerate(labels)} # Map label to index\n",
    "inv_label_map = {i: l for l, i in label_map.items()} # Map index to label\n",
    "\n",
    "print(label_map)\n",
    "print(inv_label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assemble training data into inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1685.93it/s]\n"
     ]
    }
   ],
   "source": [
    "for filename, tags in tqdm(df_train.values[:1000], miniters=1000):\n",
    "    # Read in img data\n",
    "    img = io.imread(TRAIN_TIF_DIR + \"{}.tif\".format(filename))\n",
    "    resized_img = cv2.resize(img, (32, 32))\n",
    "    # Set `targets` to one-hot encoded labels of the training data\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1\n",
    "    x_train.append(resized_img)\n",
    "    y_train.append(targets)\n",
    "\n",
    "x_train_full = np.array(x_train, np.float16)\n",
    "y_train_full = np.array(y_train, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 32, 32, 4)\n",
      "(1000, 17)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_full.shape)\n",
    "print(y_train_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure number of training inputs and validation inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_TRAIN = 500\n",
    "NUM_VALID = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish training and valiadtion data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 32, 32, 4)\n",
      "(500, 17)\n",
      "(150, 32, 32, 4)\n",
      "(150, 17)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train_full[:NUM_TRAIN]\n",
    "y_train = y_train_full[:NUM_TRAIN]\n",
    "\n",
    "x_valid = x_train_full[NUM_TRAIN:NUM_TRAIN + NUM_VALID]\n",
    "y_valid = y_train_full[NUM_TRAIN:NUM_TRAIN + NUM_VALID]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 4)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(17, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy', # For multi-class ouputs, need binary crossentropy instead of categorical crossentropy\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 150 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 0s - loss: 6.8723 - acc: 0.5695 - val_loss: 5.7849 - val_acc: 0.6384\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 0s - loss: 6.2007 - acc: 0.6120 - val_loss: 5.7849 - val_acc: 0.6384\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 0s - loss: 6.5049 - acc: 0.5934 - val_loss: 6.2176 - val_acc: 0.6118\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 0s - loss: 6.7654 - acc: 0.5771 - val_loss: 5.3049 - val_acc: 0.6690\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 0s - loss: 6.5123 - acc: 0.5929 - val_loss: 5.3049 - val_acc: 0.6690\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 0s - loss: 6.6301 - acc: 0.5855 - val_loss: 5.3049 - val_acc: 0.6690\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 0s - loss: 6.6114 - acc: 0.5867 - val_loss: 6.2427 - val_acc: 0.6102\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 0s - loss: 6.5516 - acc: 0.5904 - val_loss: 5.3049 - val_acc: 0.6690\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 0s - loss: 6.0909 - acc: 0.6192 - val_loss: 5.4307 - val_acc: 0.6612\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 0s - loss: 5.3713 - acc: 0.6644 - val_loss: 4.0728 - val_acc: 0.7459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe91e86910>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tip from forum that fbeta_score can come from `sklearn.metrics`: https://www.kaggle.com/anokas/fixed-f2-score-in-python/comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_valid = model.predict(x_valid, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(p_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.282485829564\n"
     ]
    }
   ],
   "source": [
    "print(fbeta_score(y_valid, np.array(p_valid) > 0.2, beta=2, average='samples'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
